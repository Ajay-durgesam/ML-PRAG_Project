{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8083855f",
   "metadata": {},
   "source": [
    "### Importing Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a61b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used for data manipulations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#Used for data visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Importing warnings module to prevent them from being displayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Used for Final analysis of the model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257ed4b",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a97f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Dataset : (2200, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   N            2200 non-null   int64  \n",
      " 1   P            2200 non-null   int64  \n",
      " 2   K            2200 non-null   int64  \n",
      " 3   temperature  2200 non-null   float64\n",
      " 4   humidity     2200 non-null   float64\n",
      " 5   ph           2200 non-null   float64\n",
      " 6   rainfall     2200 non-null   float64\n",
      " 7   label        2200 non-null   object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 137.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# lets read the dataset\n",
    "data = pd.read_csv(\".\\\\input\\\\Crop_recommendation.csv\")\n",
    "\n",
    "# lets check the shape of the dataset\n",
    "print(\"Shape of the Dataset :\", data.shape)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66c597",
   "metadata": {},
   "source": [
    "### Converting the columns into Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5dd6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   N            2200 non-null   int64 \n",
      " 1   P            2200 non-null   int64 \n",
      " 2   K            2200 non-null   int64 \n",
      " 3   temperature  2200 non-null   int32 \n",
      " 4   humidity     2200 non-null   int32 \n",
      " 5   ph           2200 non-null   int32 \n",
      " 6   rainfall     2200 non-null   int32 \n",
      " 7   label        2200 non-null   object\n",
      "dtypes: int32(4), int64(3), object(1)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Changing fields to numeric equivalents.(Useful while sorting the distances for finding nearest Neighbors)\n",
    "\n",
    "data['N'] = pd.to_numeric(data['N'], errors='coerce')\n",
    "data['P'] = pd.to_numeric(data['P'], errors='coerce')\n",
    "data['K'] = pd.to_numeric(data['K'], errors='coerce')\n",
    "data['temperature'] = data['temperature'].astype(int)\n",
    "data['humidity'] = data['humidity'].astype(int)\n",
    "data['ph'] = data['ph'].astype(int)\n",
    "data['rainfall'] = data['rainfall'].astype(int)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8889d8",
   "metadata": {},
   "source": [
    "## KNN Algorithm\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple yet powerful algorithm used in supervised learning for classification tasks\n",
    "\n",
    "1. **Overview**:\n",
    "   - KNN is a non-parametric algorithm, meaning it does not make any assumptions about the underlying data distribution.\n",
    "   - It is called a \"lazy learner\" because it doesn't learn a discriminative function from the training data but rather memorizes the training instances.\n",
    "   - KNN operates based on the assumption that similar instances are likely to have similar outputs.\n",
    "\n",
    "2. **How it works**:\n",
    "   - Given a new, unseen instance, KNN identifies the K nearest neighbors to that instance in the training data based on a distance metric (typically Euclidean distance).\n",
    "   - For classification tasks, the algorithm assigns the majority class among the K nearest neighbors to the new instance.\n",
    "   \n",
    "   <img src=\"./Assets/KNN_flow.png\" width=\"500\" />\n",
    "\n",
    "3. **Parameters**:\n",
    "   - K: The number of neighbors to consider. Choosing an appropriate K value is crucial; a small K can be sensitive to noise, while a large K can lead to over-smoothing.\n",
    "   - Distance metric: Typically Euclidean distance is used, but other distance metrics like Manhattan distance or cosine similarity can also be used based on the nature of the data.\n",
    "\n",
    "6. **Implementation**:\n",
    "   - Implementation involves loading the data, preprocessing (scaling, handling missing values, etc.), splitting it into training and testing sets, training the model, and evaluating its performance.\n",
    "\n",
    "7. **Evaluation**:\n",
    "   - Performance metrics for classification tasks include accuracy, precision, recall, F1-score, and ROC curves.\n",
    "\n",
    "8. **Tuning**:\n",
    "   - Hyperparameter tuning is essential, particularly for choosing the optimal K value and the appropriate distance metric.\n",
    "   - Techniques like cross-validation can be used for hyperparameter tuning.\n",
    "\n",
    "We utilize the standard Euclidean Norm, also known as the L2 Norm, as the default distance metric in our implementation.\n",
    "\n",
    "The K mentioned here is given as a parameter and is not learnt, though there are thumb rules (such as sqrt(n), n = # datapoints) and some procedures which can make better choices for K.  \n",
    "\n",
    "It's important to note that our implementation is non-parallelized, resulting in relatively slow performance. Depending on the dataset size, it may take between 5 to 15 minutes to produce results. However, the accuracy achieved by our implementation is comparable to that of standard library packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02ad3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance calculation.\n",
    "def euclidean_distance(row: pd.Series, test_row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean distance between two data points.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the training data.\n",
    "        test_row (pd.Series): A row from the test data.\n",
    "\n",
    "    Returns:\n",
    "        float: The Euclidean distance between the two data points.\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for index, value in row.items():\n",
    "        if index != 'label':\n",
    "            distance += (value - test_row[index]) ** 2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "# Manhattan distance calculation\n",
    "def manhattan_distance(row: pd.Series, test_row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Manhattan distance between two data points.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the training data.\n",
    "        test_row (pd.Series): A row from the test data.\n",
    "\n",
    "    Returns:\n",
    "        float: The Manhattan distance between the two data points.\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for index, value in row.items():\n",
    "        if index != 'label':\n",
    "            distance += abs(value - test_row[index])\n",
    "    return distance\n",
    "\n",
    "# Return the label with maximum count only.\n",
    "def get_majority_label(neighbour_list: list) -> str:\n",
    "    \"\"\"\n",
    "    Determines the majority label from a list of nearest neighbors.\n",
    "\n",
    "    Args:\n",
    "        neighbour_list (list): List of nearest neighbors with their labels.\n",
    "\n",
    "    Returns:\n",
    "        str: The majority label among the neighbors.\n",
    "    \"\"\"\n",
    "    frequency_list = []\n",
    "    for item in neighbour_list:\n",
    "        for freq_item in frequency_list:\n",
    "            if freq_item[0] == item[1]:\n",
    "                freq_item[1] += 1\n",
    "                break\n",
    "        else:\n",
    "            frequency_list.append([item[1], 1])\n",
    "    majority_label = ''\n",
    "    max_frequency = 0\n",
    "    for item in frequency_list:\n",
    "        if max_frequency < item[1]:\n",
    "            majority_label = item[0]\n",
    "            max_frequency = item[1]\n",
    "    return majority_label\n",
    "\n",
    "# For classification, calculate the distances between the new data point and all other test data points,then sort these distances and select the K nearest neighbors along with their labels.\n",
    "# Next, determine the majority label among these neighbors and assign that label to the given data point.\n",
    "\n",
    "def knn_classifier(train_data: pd.DataFrame, test_data: pd.DataFrame, k: int, metric: str) -> float:\n",
    "    \"\"\"\n",
    "    Performs K-Nearest Neighbors classification.\n",
    "\n",
    "    Args:\n",
    "        train_data (pd.DataFrame): Training data.\n",
    "        test_data (pd.DataFrame): Test data.\n",
    "        k (int): Number of neighbors to consider.\n",
    "        metric (str): Metric to use for distance calculation ('euclidean' or 'manhattan').\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy percentage of the KNN classification.\n",
    "    \"\"\"\n",
    "    total_tests = test_data.shape[0]\n",
    "    total_correct_classifications = 0\n",
    "    for _, test_row in test_data.iterrows():\n",
    "        nearest_neighbours = []\n",
    "        for _, train_row in train_data.iterrows():\n",
    "            if metric == 'euclidean': # for euclidean metric\n",
    "                nearest_neighbours.append((euclidean_distance(train_row, test_row), train_row['label']))\n",
    "            elif metric == 'manhattan': # for manhattan metric\n",
    "                nearest_neighbours.append((manhattan_distance(train_row, test_row), train_row['label']))\n",
    "            else:\n",
    "                raise ValueError(\"Invalid metric. Please use 'euclidean' or 'manhattan'.\")\n",
    "        nearest_neighbours.sort()\n",
    "        nearest_neighbours = nearest_neighbours[:k-1]\n",
    "        if test_row['label'] == get_majority_label(nearest_neighbours):\n",
    "            total_correct_classifications += 1\n",
    "    return (total_correct_classifications / total_tests) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38374881",
   "metadata": {},
   "source": [
    "### Data Splitting into train, validation and test\n",
    "\n",
    "1. **Training Set**: \n",
    "   - Purpose: The training set is used to train the machine learning model. It contains labeled data points that the model uses to learn patterns and relationships between features and their corresponding labels.\n",
    "   - Importance: Training on a sufficiently large and diverse training set helps the model generalize well to unseen data and learn robust patterns in the data.\n",
    "\n",
    "2. **Validation Set**: \n",
    "   - Purpose: The validation set is used to evaluate the performance of the trained model during its development and tuning phase. It helps in comparing different models or variations of the same model and tuning hyperparameters.\n",
    "   - Importance: By evaluating the model on a separate validation set, we can detect overfitting, select the best-performing model, and tune hyperparameters for optimal performance.\n",
    "\n",
    "3. **Test Set**: \n",
    "   - Purpose: The test set is used to provide an unbiased evaluation of the final trained model's performance. It contains labeled data points that the model has not seen during training or validation.\n",
    "   - Importance: Evaluating the model on a separate test set helps in assessing its generalization ability and estimating its performance on unseen data. It provides a realistic estimate of how well the model is likely to perform in real-world scenarios.\n",
    "\n",
    "Splitting the data into these three sets helps in ensuring that the machine learning model is trained, validated, and tested properly, following best practices in model development and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2145bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 70-15-15 as train, validation, and test data sets\n",
    "train_set = data.sample(frac=0.7, random_state=8)\n",
    "remaining_data = data.drop(train_set.index)\n",
    "\n",
    "validation_set = remaining_data.sample(frac=0.5, random_state=8)\n",
    "test_set = remaining_data.drop(validation_set.index)\n",
    "\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "validation_set = validation_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Parameter K: first choice\n",
    "K = math.ceil(math.sqrt(train_set.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ca2c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1540, 8)\n",
      "Validation set shape: (330, 8)\n",
      "Test set shape: (330, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set shape:\", train_set.shape)\n",
    "print(\"Validation set shape:\", validation_set.shape)\n",
    "print(\"Test set shape:\", test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edecc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN:  93.93939393939394\n"
     ]
    }
   ],
   "source": [
    "#Knn function call\n",
    "\n",
    "#initially we are using Euclidean metric only\n",
    "print(\"Accuracy of KNN: \",knn_classifier(train_set,test_set,k=K,metric='euclidean'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
